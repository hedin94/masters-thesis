%%% lorem.tex --- 
%% 
%% Filename: lorem.tex
%% Description: 
%% Author: Ola Leifler
%% Maintainer: 
%% Created: Wed Nov 10 09:59:23 2010 (CET)
%% Version: $Id$
%% Version: 
%% Last-Updated: Tue Oct  4 11:58:17 2016 (+0200)
%%           By: Ola Leifler
%%     Update #: 7
%% URL: 
%% Keywords: 
%% Compatibility: 
%% 
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
%% 
%%% Commentary: 
%% 
%% 
%% 
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
%% 
%%% Change log:
%% 
%% 
%% RCS $Log$
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
%% 
%%% Code:

\chapter{Theory} \label{ch:theory}

Since several mesh simplification algorithms are being considered, Section~\ref{sec:mesh_simplification} presents the most notable schemes found (through peer-reviewed surveys) in previous work. An outline of the algorithm and the results found by authors are given for the reader's convenience, and also to be used as a guideline when implementing the solutions into Configura's CG pipeline.

Afterwards, in Section~\ref{sec:metrics_for_appearance_preservation}, we discuss the different metrics that can be used to measure the appearance preservation after a simplification has been done. This will later be used to evaluate the solutions and provide an empirical way to answer research questions 2 and 3 by giving a concrete metric for appearance thresholds and the amount of appearance deviation.

Finally, in Section~\ref{sec:measuring_algorithmic_performance}, the methods and common practices for measuring performance of an algorithm are discussed. Based on existing industry practices, we show how to measure the computation time and memory usage of the algorithms. Since these measurements can be noisy, statistical methods will need to be used to truthfully answer our research questions.

\section{Mesh Simplification} \label{sec:mesh_simplification}

According to \emph{David Luebke's survey}~\cite{luebke2001developer} on the subject, mesh simplification is a technique which transforms a geometrically complex mesh (with a lot of polygons) to a simpler representation by removing unimportant geometrical details (reducing the number of polygons). It does this by assuming that some meshes are small, distant, or have areas which are unimportant to the visual quality of the rendered image. For example, if the camera in a scene always faces towards a certain direction, then removing details from the backside of a mesh won't affect the final rendered result, since they will never be seen by the camera anyway. Reducing the number of polygons allows meshes to use less storage space and need less computation time.

There are many mesh simplification algorithms, as can be seen in \emph{David Luebke's survey}~\cite{luebke2001developer}, each presenting a new approach with their own strengths and weaknesses. The first scheme is due to \emph{Schroeder et al.}~\cite{schroeder1992decimation} in 1992, called \emph{mesh decimation}. It was meant to be used to simplify meshes produced by the marching cubes algorithm, which usually gives unnecessary details. It works by making multiple passes through the meshes' vertices, and deleting vertices that don't destroy local topology and are within a given distance threshold when re-triangulated.

While the scheme above is simple and fast, it unfortunately doesn't give a geometrically optimal simplification. But by using \emph{quadric error metrics}, which we discuss on the next page, it is possible to achieve such an optimal result. We then consider texture preserving simplifiers.

\subsection{Quadric-Based Error Metric} \label{sec:quadric-based_error_metric}

\[\bar{\mathbf{v}}_i = \begin{bmatrix}
    q_{11} & q_{12} & q_{13} & q_{14}\\
    q_{21} & q_{22} & q_{23} & q_{24}\\
    q_{31} & q_{32} & q_{33} & q_{34}\\
    0 & 0 & 0 & 1\\
\end{bmatrix}^{-1} \begin{bmatrix} 0 \\
                                   0 \\
                                   0 \\
                                   1 \end{bmatrix} \; ,\]

\[\Delta(\mathbf{v}_i) = \mathbf{v}_i^\intercal \mathbf{Q}_i  \mathbf{v}_i \;\;,\;\; \mathbf{Q}_i = \sum_{f_k \in N_i}  \mathbf{f_k} \mathbf{f_k}^\intercal\]

\begin{figure}[h]
    \centering
    \begin{minipage}{0.49\textwidth}
        \centering
        \includegraphics[width=\textwidth]{figures/contraction_types.eps}
        \caption{(a) edge \(e_{ji} = (v_j, v_i)\) contraction towards \(v_i\)
                 and (b) pair \((v_j, v_k)\) contraction in the distance threshold \(t\) toward new vertex \(v_i\).}
        \label{fig:contractions}
    \end{minipage} \hfill
    \begin{minipage}{0.485\textwidth}
        \centering
        \includegraphics[width=\textwidth]{figures/quadric_planes.eps}
        \caption{depiction of one of the planes \(f_k\) in the neighborhood \(N_i\) of the vertex \(v_i\). It has a normal \(\mathbf{\hat{n}}_k\); found by the \(\mathbf{\hat{w}}_k \times \mathbf{\hat{u}}_k\) of its edges.}
        \label{fig:quadrics}
    \end{minipage}
\end{figure}

\begin{figure}[h]
    \centering
    \includegraphics[width=\textwidth]{figures/naive_simplification.png}
    \includegraphics[width=\textwidth]{figures/quadric_simplification.png}
    \caption{simplification using a na\"ive (top image) and a quadric error metric (bottom image) at different levels of detail at some vertex count (left to right: 50 \%, 35 \% and 17 \% of original).}
    \label{fig:naive_vs_quadric}
\end{figure}

\subsection{Appearance-Preserving Simplification} \label{sec:appearance-preserving_simplification}
In order to preserve the appearance of a model when it is simplified, \emph{Cohen et al.} \cite{cohen1998appearance} defines a new \emph{texture deviation metric}. This metric takes three attributes into account: Surface position, surface curvature, and surface color. To properly sample these attributes from the input surface, the surface position is decoupled from the color and normals stored in texture and normal maps, respecticely. The metric guarantees that the maps will not shift more than a user-specified number of pixels on the screen $\epsilon$.

Approximation of the surface position is done offline with simplification operations such as edge collapsing and vertex removals. At run-time, the color and normals are sampled in pixel-coordinated with mip-mapping techniques. Here the decoupled representation is useful since the texture deviation metric can be used to bound how much the mapped attributes value's positions deviate from the positions of the original mesh. This gurantees that the sampling and mapping to screen-space of the attribues is done in an appropriate way.

Before any simplification can be made, a parametrization of the surface is required in order to store the color and normals in maps. If the input mesh does not have a parametrization, it is created and stored per-vertex in texture and normal maps. Next, the surface and maps are fed into the simplification algorithm which decides which simplification operations to use and in what order. The deviation caused by each operation is measured with the texture deviation metric. A \emph{progressive mesh} (PM) with error bounds for each operation is returned by the algorithm which can then be used to create a set of LOD with error bounds. Using the error bounds, the tesselation of the model can be adjusted to meet the user-specified error $\epsilon$.

\subsection{Texture Mapped Progressive Meshing} \label{sec:texture_mapped_progressive_meshing}
Given an arbitrary mesh, \emph{Sander et. al} \cite{sander2001texture} presents a method to construct a PM where a texture parametrization is shared between all meshes in a PM sequence. In order to create a texture mapping for a simplified mesh, the original mesh's attributes, e.g normals, is sampled. This method was developed with two goals taken into consideration:
\begin{itemize}
\item{Minimize \emph{texture stretch}:}~~~When a mesh is simplified the texture may be stretched in some areas which decrease the quality of the appearance. Since the texture parametrization determines the sampling density, a balanced parametrization is prefered over one that samples with different density in different areas. The balanced parametrization is obtained by minimizing the largest texture stretch over all points in the domain. No point in the domain will therefore not be too stretched and thus making no point undersampled. 
\item{Minimize \emph{texture deviation}:}~~~Conventional methods use geometric error for the mesh simplification. According to the authors this is not appropriate when a mesh is textured. The stricter texture deviation error metric, where the geometric error is measured according to the parametrization, is more appropriate. This is the metric by \emph{Cohen et al.} \cite{cohen1998appearance} explained in \ref{sec:appearance-preserving_simplification}. By plotting a graph of the texture deviation vs the number of faces, the goal is to minimize the height of this graph.
\end{itemize}

\emph{Cohen et al.} \cite{cohen1998appearance} stored an error bound for each vertex in a PM. \emph{Sander et al.} \cite{sander2001texture} instead tries to find an atlas parametrization that minimizes both texture deviation and texture stretch for all meshes in the PM. 

\section{Metrics for Appearance Preservation} \label{sec:metrics_for_appearance_preservation}
Previously \ref{sec:appearance-preserving_simplification}\ref{sec:texture_mapped_progressive_meshing}, the metrics texture deviation and texture stretch have been defined. But to measure more exactly how much the visual appearance of a simplified mesh deviate from the original mesh another metric would be better. \emph{Lindstrom and Turk} \cite{lindstrom2000image} defines \emph{Image-driven simplification} which captures images from different angles of the mesh. The difference between the images of the original and simplified mesh are computed in order to measure how well the appearance is preserved. This metric is more general and can be applied to all meshes.

The \emph{image metric} is defined as a function taking two images and gives the distance between them. To measure the distance the authors use root mean square of the luminance values of two images $Y^0$ and $Y^1$ with dimensions $m \times n$ pixels. It is defined as:
\begin{equation*}
  d_{RMS}(Y^0,Y^1) = \sqrt{\tfrac{1}{mn}\sum^m_{i=1}\sum^n_{j=1}(y^0_{ij} - y^1_{ij})^2}
\end{equation*}

To evaluate the quality of the simplified mesh the authors capture images from 24 different camera positions. The positions are defined as the vertices of a rhombicuboctahedron. Two sets of $l$ images $Y^0 = {Y^0_h}$ and $Y^1 = {Y^1_h}$ with dimensions $m \times n$ is rendered and the RMS is then computed as:
\begin{equation*}
  d_{RMS}(Y^0,Y^1) = \sqrt{\tfrac{1}{lmn}\sum^l_{h=1}\sum^m_{i=1}\sum^n_{j=1}(y^0_{ij} - y^1_{ij})^2}
\end{equation*}

\section{Measuring Algorithmic Performance} \label{sec:measuring_algorithmic_performance}

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
%%% theory.tex ends here

%%% Local Variables: 
%%% mode: latex
%%% TeX-master: "thesis"
%%% End: 
